# Copyright (c) SenseTime. All Rights Reserved.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

from yacs.config import CfgNode as CN

__C = CN()

cfg = __C

__C.META_ARC = "siamban_r50_l234"

__C.CUDA = True

# ------------------------------------------------------------------------ #
# Training options
# ------------------------------------------------------------------------ #
__C.TRAIN = CN()

# Number of negative
__C.TRAIN.NEG_NUM = 16

# Number of positive
__C.TRAIN.POS_NUM = 16

# Number of anchors per images
__C.TRAIN.TOTAL_NUM = 64


__C.TRAIN.EXEMPLAR_SIZE = 127

__C.TRAIN.SEARCH_SIZE = 255
__C.TRAIN.SEARCH_DET_SIZE = 255


__C.TRAIN.BASE_SIZE = 8

__C.TRAIN.OUTPUT_SIZE = 25
__C.TRAIN.OUTPUT_SIZE_DET = 19


__C.TRAIN.RESUME = ''

__C.TRAIN.PRETRAINED = ''

__C.TRAIN.LOG_DIR = './logs'

__C.TRAIN.SNAPSHOT_DIR = './snapshot'

__C.TRAIN.EPOCH = 20

__C.TRAIN.START_EPOCH = 0

__C.TRAIN.BATCH_SIZE = 32

__C.TRAIN.NUM_WORKERS = 1

__C.TRAIN.MOMENTUM = 0.9

__C.TRAIN.WEIGHT_DECAY = 0.0001

__C.TRAIN.CLS_WEIGHT = 1.0

__C.TRAIN.LOC_WEIGHT = 1.0

__C.TRAIN.RANK_CLS_WEIGHT = 0.5

__C.TRAIN.RANK_IGR_WEIGHT = 0.25

__C.TRAIN.HARD_NEGATIVE_THS = 0.5

__C.TRAIN.RANK_NUM_HARD_NEGATIVE_SAMPLES = 8

__C.TRAIN.IoU_Gamma = 3

__C.TRAIN.HARD_NEGATIVE_THS = 0.5

__C.TRAIN.PRINT_FREQ = 20

__C.TRAIN.LOG_GRADS = False

__C.TRAIN.GRAD_CLIP = 10.0

__C.TRAIN.BASE_LR = 0.005

__C.TRAIN.LR = CN()

__C.TRAIN.LR.TYPE = 'log'

__C.TRAIN.LR.KWARGS = CN(new_allowed=True)

__C.TRAIN.LR_WARMUP = CN()

__C.TRAIN.LR_WARMUP.WARMUP = True

__C.TRAIN.LR_WARMUP.TYPE = 'step'

__C.TRAIN.LR_WARMUP.EPOCH = 5

__C.TRAIN.LR_WARMUP.KWARGS = CN(new_allowed=True)

__C.TRAIN.DATA_NORMALIZE = True
__C.TRAIN.DATA_NORMALIZE_MODE = 1
__C.TRAIN.FLAG_SIGMOID_LOSS = True
__C.TRAIN.CODE_TIME_TAGE = 'T0'
__C.TRAIN.FLAG_LOCPREDMODE = 0
__C.TRAIN.TYPE_ACM = 0
__C.TRAIN.CONVTYPE_XORR = 0
__C.TRAIN.FLAG_REPARAMETERALL = False
__C.TRAIN.MODE_REPARAMETERIZE = 0

__C.TRAIN.NORM_REG_TARGETS = True
__C.TRAIN.CENTER_SAMPLING_RADIUS = 1.5
__C.TRAIN.FPN_STRIDES = [8,]
__C.TRAIN.IOU_LOSS_TYPE = 'giou'
__C.TRAIN.CENTER_SAMPLING_RADIUS = 1.5
__C.TRAIN.FOCAL_ALPHA = 0.25
__C.TRAIN.FOCAL_GAMA = 2.0
__C.TRAIN.OBJECT_SIZES_OF_INTEREST = [16,255]
__C.TRAIN.NUM_CLASSES = 200
__C.TRAIN.FLAG_FOCAL_LOSS = True



# ------------------------------------------------------------------------ #
# Dataset options
# ------------------------------------------------------------------------ #
__C.DATASET = CN(new_allowed=True)

# Augmentation
# for template
__C.DATASET.TEMPLATE = CN()

# Random shift see [SiamPRN++](https://arxiv.org/pdf/1812.11703)
# for detail discussion
__C.DATASET.TEMPLATE.SHIFT = 4
__C.DATASET.TEMPLATE.SHIFT_RATIO = 0.01

__C.DATASET.TEMPLATE.SCALE = 0.05

__C.DATASET.TEMPLATE.BLUR = 0.0

__C.DATASET.TEMPLATE.FLIP = 0.0

__C.DATASET.TEMPLATE.COLOR = 1.0

__C.DATASET.SEARCH = CN()

__C.DATASET.SEARCH.SHIFT = 64

__C.DATASET.SEARCH.SCALE = 0.18
__C.DATASET.SEARCH.SCALE_MIN = 1.0
__C.DATASET.SEARCH.SCALE_MAX = 1.0
__C.DATASET.SEARCH.SCALE_HWRATIO = 0.1

__C.DATASET.SEARCH.BLUR = 0.0

__C.DATASET.SEARCH.FLIP = 0.0

__C.DATASET.SEARCH.COLOR = 1.0

__C.DATASET.SEARCH.PROB_RANDEREASE = 0.0
__C.DATASET.SEARCH.SCALEMIN_RANDEREASE = 0.0
__C.DATASET.SEARCH.SCALEMAX_RANDEREASE = 0.0

__C.DATASET.SEARCH.MINSIZE_TARGET = 16
__C.DATASET.SEARCH.NUM_REPEATE = 6

__C.DATASET.PERSONTK = CN()
__C.DATASET.PERSONTK.FLAG_ENCODEGTASDET = 1

# Sample Negative pair see [DaSiamRPN](https://arxiv.org/pdf/1808.06048)
# for detail discussion
__C.DATASET.NEG = 0.2
__C.DATASET.NUM_NEG = 1
__C.DATASET.NUM_POS = 1
__C.DATASET.POSNEG_MODE = 0
__C.DATASET.NUM_TEMPLATE = 0
__C.DATASET.NUM_SEARCH = 0


# improve tracking performance for otb100
__C.DATASET.GRAY = 0.0

__C.DATASET.NAMES = ('VID', 'YOUTUBEBB', 'DET', 'COCO', 'GOT10K', 'LASOT','REMOCATDOGHORSE','HeadNOFACECOCO','HeadNOFACEAIC')

# __C.DATASET.VID = CN()
# __C.DATASET.VID.ROOT = 'training_dataset/vid/crop511'
# __C.DATASET.VID.ANNO = 'training_dataset/vid/train.json'
# __C.DATASET.VID.FRAME_RANGE = 100
# __C.DATASET.VID.NUM_USE = 100000
#
# __C.DATASET.YOUTUBEBB = CN()
# __C.DATASET.YOUTUBEBB.ROOT = 'training_dataset/yt_bb/crop511'
# __C.DATASET.YOUTUBEBB.ANNO = 'training_dataset/yt_bb/train.json'
# __C.DATASET.YOUTUBEBB.FRAME_RANGE = 3
# __C.DATASET.YOUTUBEBB.NUM_USE = 200000
#
# __C.DATASET.COCO = CN()
# __C.DATASET.COCO.ROOT = 'training_dataset/coco/crop511'
# __C.DATASET.COCO.ANNO = 'training_dataset/coco/train2017.json'
# __C.DATASET.COCO.FRAME_RANGE = 1
# __C.DATASET.COCO.NUM_USE = 100000
#
# __C.DATASET.DET = CN()
# __C.DATASET.DET.ROOT = 'training_dataset/det/crop511'
# __C.DATASET.DET.ANNO = 'training_dataset/det/train.json'
# __C.DATASET.DET.FRAME_RANGE = 1
# __C.DATASET.DET.NUM_USE = 200000
#
# __C.DATASET.GOT10K = CN()
# __C.DATASET.GOT10K.ROOT = 'training_dataset/got_10k/crop511'
# __C.DATASET.GOT10K.ANNO = 'training_dataset/got_10k/train.json'
# __C.DATASET.GOT10K.FRAME_RANGE = 100
# __C.DATASET.GOT10K.NUM_USE = 200000
#
# __C.DATASET.LASOT = CN()
# __C.DATASET.LASOT.ROOT = 'training_dataset/lasot/crop511'
# __C.DATASET.LASOT.ANNO = 'training_dataset/lasot/train.json'
# __C.DATASET.LASOT.FRAME_RANGE = 100
# __C.DATASET.LASOT.NUM_USE = 200000

__C.DATASET.VID = CN()
__C.DATASET.VID.ROOT = '/home/zhangming/Models2/Datasets/GOT/ILSVRC2015/crop511'
__C.DATASET.VID.ANNO = '/home/zhangming/Models2/Datasets/GOT/ILSVRC2015/train.json'
__C.DATASET.VID.FRAME_RANGE = 100
__C.DATASET.VID.NUM_USE = 100000
__C.DATASET.VID.NUM_USE_DOG = 100000
__C.DATASET.VID.NUM_USE_CAT = 100000
__C.DATASET.VID.NUM_USE_HORSE = 100000
__C.DATASET.VID.NUM_USE_OTHER = 100000

__C.DATASET.YOUTUBEBB = CN()
__C.DATASET.YOUTUBEBB.ROOT = '/home/zhangming/Models2/Datasets/GOT/youtube/youtube_new'
__C.DATASET.YOUTUBEBB.ANNO = '/home/zhangming/Models2/Datasets/GOT/youtube/train.json'
__C.DATASET.YOUTUBEBB.FRAME_RANGE = 3
__C.DATASET.YOUTUBEBB.NUM_USE = 200000
__C.DATASET.YOUTUBEBB.NUM_USE_DOG = 100000
__C.DATASET.YOUTUBEBB.NUM_USE_CAT = 100000
__C.DATASET.YOUTUBEBB.NUM_USE_HORSE = 100000
__C.DATASET.YOUTUBEBB.NUM_USE_OTHER = 100000

__C.DATASET.COCO = CN()
__C.DATASET.COCO.ROOT = '/home/zhangming/Models2/Datasets/GOT/coco/crop511'
__C.DATASET.COCO.ANNO = '/home/zhangming/Models2/Datasets/GOT/coco/train2017.json'
__C.DATASET.COCO.FRAME_RANGE = 1
__C.DATASET.COCO.NUM_USE = 100000
__C.DATASET.COCO.NUM_USE_DOG = 100000
__C.DATASET.COCO.NUM_USE_CAT = 100000
__C.DATASET.COCO.NUM_USE_HORSE = 100000
__C.DATASET.COCO.NUM_USE_OTHER = 100000

__C.DATASET.DET = CN()
__C.DATASET.DET.ROOT = '/home/zhangming/Models2/Datasets/GOT/ImageNetDet/crop511'
__C.DATASET.DET.ANNO = '/home/zhangming/Models2/Datasets/GOT/ImageNetDet/train.json'
__C.DATASET.DET.FRAME_RANGE = 1
__C.DATASET.DET.NUM_USE = 200000
__C.DATASET.DET.NUM_USE_DOG = 100000
__C.DATASET.DET.NUM_USE_CAT = 100000
__C.DATASET.DET.NUM_USE_HORSE = 100000
__C.DATASET.DET.NUM_USE_OTHER = 100000

__C.DATASET.GOT10K = CN()
__C.DATASET.GOT10K.ROOT = '/home/zhangming/Models2/Datasets/GOT/GOT10K/got10k/crop511'
__C.DATASET.GOT10K.ANNO = '/home/zhangming/Models2/Datasets/GOT/GOT10K/got10k/train.json'
__C.DATASET.GOT10K.FRAME_RANGE = 100
__C.DATASET.GOT10K.NUM_USE = 200000
__C.DATASET.GOT10K.NUM_USE_DOG = 100000
__C.DATASET.GOT10K.NUM_USE_CAT = 100000
__C.DATASET.GOT10K.NUM_USE_HORSE = 100000
__C.DATASET.GOT10K.NUM_USE_OTHER = 100000

__C.DATASET.LASOT = CN()
__C.DATASET.LASOT.ROOT = '/home/zhangming/Models2/Datasets/GOT/LaSOT/crop511'
__C.DATASET.LASOT.ANNO = '/home/zhangming/Models2/Datasets/GOT/LaSOT/train.json'
__C.DATASET.LASOT.FRAME_RANGE = 100
__C.DATASET.LASOT.NUM_USE = 200000
__C.DATASET.LASOT.NUM_USE_DOG = 100000
__C.DATASET.LASOT.NUM_USE_CAT = 100000
__C.DATASET.LASOT.NUM_USE_HORSE = 100000
__C.DATASET.LASOT.NUM_USE_OTHER = 100000

__C.DATASET.HeadNOFACECOCO = CN()
__C.DATASET.HeadNOFACECOCO.ROOT = '/home/zhangming/Models2/Datasets/GOT/LaSOT/crop511'
__C.DATASET.HeadNOFACECOCO.ANNO = '/home/zhangming/Models2/Datasets/GOT/LaSOT/train.json'

__C.DATASET.HeadNOFACEAIC = CN()
__C.DATASET.HeadNOFACEAIC.ROOT = '/home/zhangming/Models2/Datasets/GOT/LaSOT/crop511'
__C.DATASET.HeadNOFACEAIC.ANNO = '/home/zhangming/Models2/Datasets/GOT/LaSOT/train.json'


__C.DATASET.REMOCATDOGHORSE = CN()
__C.DATASET.REMOCATDOGHORSE.ROOT = '/home/zhangming/Models2/Datasets/GOT/LaSOT/crop511'
__C.DATASET.REMOCATDOGHORSE.ANNO = '/home/zhangming/Models2/Datasets/GOT/LaSOT/train.json'
__C.DATASET.REMOCATDOGHORSE.FRAME_RANGE = 100
__C.DATASET.REMOCATDOGHORSE.NUM_USE = 200000
__C.DATASET.REMOCATDOGHORSE.NUM_USE_DOG = 100000
__C.DATASET.REMOCATDOGHORSE.NUM_USE_CAT = 100000
__C.DATASET.REMOCATDOGHORSE.NUM_USE_HORSE = 100000
__C.DATASET.REMOCATDOGHORSE.NUM_USE_OTHER = 100000


__C.DATASET.VIDEOS_PER_EPOCH = 1000000
__C.DATASET.FLAG_CHANGEPADDING = True
__C.DATASET.CHANGEPADDING_VALUE = (117,117,117)
__C.DATASET.DATASETID = 0

__C.DATASET.FILE_CLSTAG2CLASSID_CLSTRACKER = ''


__C.DATASET.CATDOGHORSETK = CN()
__C.DATASET.CATDOGHORSETK.DATASET_ROOT = ''
__C.DATASET.CATDOGHORSETK.IMAGE_LIST = ()
__C.DATASET.CATDOGHORSETK.DATASET_ROOT_OTHERIMAGE = ""
__C.DATASET.CATDOGHORSETK.IMAGE_LIST_OTHER = ""
__C.DATASET.CATDOGHORSETK.VID_LIST = ()
__C.DATASET.CATDOGHORSETK.KCONTEXTFACTOR = 0.5
__C.DATASET.CATDOGHORSETK.KCONTEXTFACTORSHIFTBOX = 2.0
__C.DATASET.CATDOGHORSETK.VIDEOS_PER_EPOCH = 600000
__C.DATASET.CATDOGHORSETK.CHANGEPADDING_VALUE = (104,117,123)
__C.DATASET.CATDOGHORSETK.GRAY = 0.0
__C.DATASET.CATDOGHORSETK.FETCH_ITERS = 1
__C.DATASET.CATDOGHORSETK.NBATCH_SHAPREPREV = 1
__C.DATASET.CATDOGHORSETK.NUM_GENERATE_PER_IMAGE = 12
__C.DATASET.CATDOGHORSETK.NUM_GENERATE_PER_FRAME = 12

__C.DATASET.CATDOGHORSETK.NUM_NEG_GENERATE_PER_IMAGE = 6
__C.DATASET.CATDOGHORSETK.NUM_NEG_GENERATE_PER_FRAME = 6
__C.DATASET.CATDOGHORSETK.NUM_NEG_OTHEROBJECT = 6
__C.DATASET.CATDOGHORSETK.PROB_NEG_OTHEROBJECT = 0.5
__C.DATASET.CATDOGHORSETK.NUM_FEATCH_SEG = 5
__C.DATASET.CATDOGHORSETK.NUM_DET = 1

__C.DATASET.CATDOGHORSETK.SEGGT_SIZE = 39

__C.DATASET.CATDOGHORSETK.TYPE_CONTEXTBOX = 0
__C.DATASET.CATDOGHORSETK.ID_PREVIMAGESHARE= -1
__C.DATASET.CATDOGHORSETK.FLAG_ENCODEGTASDET = False
__C.DATASET.CATDOGHORSETK.FLIP_TEMPLATE = 0.0
__C.DATASET.CATDOGHORSETK.FLIPVER_TEMPLATE = 0.0
__C.DATASET.CATDOGHORSETK.FLIP_SEARCH = 0.0
__C.DATASET.CATDOGHORSETK.FLIPVER_SEARCH = 0.0
__C.DATASET.CATDOGHORSETK.ROTATE_SEARCH = 0.0
__C.DATASET.CATDOGHORSETK.CROP_TEMPLATE = 0.0
__C.DATASET.CATDOGHORSETK.CROP_SCALE = 0.8

__C.DATASET.CATDOGHORSETK.NEG = 0.2
__C.DATASET.CATDOGHORSETK.PERSON_PROB = 1.0
__C.DATASET.CATDOGHORSETK.FLAG_NEGSEARCHAUG = True
__C.DATASET.CATDOGHORSETK.FLAG_TEMPLATESEARCH_SIZEFROMCONFIG = False

__C.DATASET.CATDOGHORSETK.TRIP_REPEATE_NUM = 3

__C.DATASET.CATDOGHORSETK.PROB_EREASE_BOTTOM = 0.0
__C.DATASET.CATDOGHORSETK.SCALE_EREASE_BOTTOM = 0.4
__C.DATASET.CATDOGHORSETK.PROB_NEGFROM_HEADNOFACE = 0.0
__C.DATASET.CATDOGHORSETK.PROB_PUTHEADONSEARCH = 0.0

__C.DATASET.CATDOGHORSETK.FLAG_TEMPLATEFROMIMG = False
__C.DATASET.CATDOGHORSETK.PROB_TEMPLATEFROMIMG = 0.5
__C.DATASET.CATDOGHORSETK.PROB_IMG = 0.2
__C.DATASET.CATDOGHORSETK.POSNEG_MODE = 0
__C.DATASET.CATDOGHORSETK.SHIFT_MODE = 0
__C.DATASET.CATDOGHORSETK.LAMBDA_MIN_SCALE = -0.4
__C.DATASET.CATDOGHORSETK.LAMBDA_MAX_SCALE = 0.4
__C.DATASET.CATDOGHORSETK.LAMBDA_MIN_RATIO = -0.2
__C.DATASET.CATDOGHORSETK.LAMBDA_MAX_RATIO = 0.2
__C.DATASET.CATDOGHORSETK.LAMBDA_SHIFT = 5.0
__C.DATASET.CATDOGHORSETK.LAMBDA_SCALE = 15.0
__C.DATASET.CATDOGHORSETK.COVEA = 0.5

__C.DATASET.CATDOGHORSETK.PROB_CROPTEMPLATE = 0.0
__C.DATASET.CATDOGHORSETK.SCALE_CROPTEMPLATE = 0.0
__C.DATASET.CATDOGHORSETK.DET_SAMPLERADIUS = 1.5

__C.DATASET.CATDOGHORSETKREID= CN()
__C.DATASET.CATDOGHORSETKREID.NUM_IDS = 16
__C.DATASET.CATDOGHORSETKREID.NUM_PERID = 4


# ------------------------------------------------------------------------ #
# Backbone options
# ------------------------------------------------------------------------ #
__C.BACKBONE = CN()

# Backbone type, current only support resnet18,34,50;alexnet;mobilenet
__C.BACKBONE.TYPE = 'mobilenetv2'

__C.BACKBONE.KWARGS = CN(new_allowed=True)
__C.BACKBONE.KWARGS.used_layers = [3,5,7]
# __C.BACKBONE.KWARGS.width_mult = 1.0
# __C.BACKBONE.KWARGS.flaglastconv = False

# Pretrained backbone weights
__C.BACKBONE.PRETRAINED = ''

__C.BACKBONE.PRETRAINED_Mode = 0


# Train layers
__C.BACKBONE.TRAIN_LAYERS = ['layer2', 'layer3', 'layer4']

# Layer LR
__C.BACKBONE.LAYERS_LR = 0.1

# Switch to train layer
__C.BACKBONE.TRAIN_EPOCH = 5
__C.BACKBONE.TRAIN_START_LAYER = 4

# ------------------------------------------------------------------------ #
# Adjust layer options
# ------------------------------------------------------------------------ #
__C.ADJUST = CN()

# Adjust layer
__C.ADJUST.ADJUST = True

__C.ADJUST.KWARGS = CN(new_allowed=True)
#__C.ADJUST.KWARGS.in_channels = [32,96,320]
#__C.ADJUST.KWARGS.out_channels = [256,256,256]
#__C.ADJUST.KWARGS.weighted = True

# Adjust layer type
__C.ADJUST.TYPE = "MultiAdjustLayer"

# ------------------------------------------------------------------------ #
# BAN options
# ------------------------------------------------------------------------ #
__C.BAN = CN()

# Whether to use ban head
__C.BAN.BAN = True

# BAN type
__C.BAN.TYPE = 'DepthwiseBAN'

__C.BAN.KWARGS = CN(new_allowed=True)
#__C.BAN.KWARGS.in_channels = 256
#__C.BAN.KWARGS.out_channels = 256
#__C.BAN.KWARGS.cls_out_channels = 2
__C.BAN.channels = 256
# ------------------------------------------------------------------------ #
# Point options
# ------------------------------------------------------------------------ #
__C.POINT = CN()

# Point stride
__C.POINT.STRIDE = 8
__C.POINT.SCALE_POS = 4.0
__C.POINT.SCALE_NEG = 2.0



# ------------------------------------------------------------------------ #
# Tracker options
# ------------------------------------------------------------------------ #
__C.TRACK = CN()

__C.TRACK.TYPE = 'SiamBANTracker'

# Scale penalty
__C.TRACK.PENALTY_K = 0.14

# Window influence
__C.TRACK.WINDOW_INFLUENCE = 0.45

# Interpolation learning rate
__C.TRACK.LR = 0.30

# Exemplar size
__C.TRACK.EXEMPLAR_SIZE = 127

# Instance size
__C.TRACK.INSTANCE_SIZE = 255

# Base size
__C.TRACK.BASE_SIZE = 8

# Context amount
__C.TRACK.CONTEXT_AMOUNT = 0.5
